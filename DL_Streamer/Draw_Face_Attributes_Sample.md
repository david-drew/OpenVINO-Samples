# Face Detection And Classification Python Sample

The Face Detection And Classification Python sample shows you how to create and control a GStreamer pipeline from a C++ application, and how to access metadata generated by inference elements and attached to image buffer.

## How It Works
The sample uses the `gst_parse_launch` GStreamer function to construct a pipeline from a string representation. The callback function is set on the `gvawatermark` element source pin in the pipeline.

A callback is invoked on every frame. The callback loops through inference metadata attached to the frame, converts raw tensor data to text labels, and displays a label for detected objects. This sample doesn't contain `.json` files with post-processing rules because the sample post-processes classification results in the callback function.

## Models

The sample uses the following pre-trained models from the OpenVINO™ toolkit [Open Model Zoo](https://github.com/opencv/open_model_zoo)
	*   __face-detection-adas-0001__ is the primary detection network to finding faces
	*   __age-gender-recognition-retail-0013__ estimates age and gender on the faces
	*   __emotions-recognition-retail-0003__ estimates the emotion on the faces
	*   __facial-landmarks-35-adas-0002-0009__ generates facial landmark points
	*   __head-pose-estimation-adas-0001__ estimates the head pose

## Running

1. If you have not done so already, download the models required for this and other samples:

	```sh
	/opt/intel/openvino/data_processing/dl_streamer/samples/download_models.sh
	```
	
2. Run the sample script:
	```sh
	./build_and_run.sh [INPUT_VIDEO]
	```

	The [INPUT_VIDEO] lets you specify a video source. Your options are:
		* A local video file for which you specify the path and file name
		* A Web camera device, such as `/dev/video0`
		* An RTSP camera that uses an URL that starts with `rtsp://`
		* Another streaming source that uses an URL that starts with `http://`

	If you don't include the [INPUT_VIDEO] parameter, the sample uses the `urisourcebin` element to stream a video from sn https link. This requires an Internet connection.

	The C++ sample is compiled in a directory under `$HOME/intel/dl_streamer` and then the executable is run.

## Output

This sample:
	* displays the GSreamer pipeline string as passed to function `gst_parse_launch`
	* starts the pipeline and displays the video with bounding boxes around detected faces, facial landmarks points, head pose, and text with classification results for each detected face. The classification results include age, gender, and emotion.

## See also
* [DL Streamer samples](../../README.md)
